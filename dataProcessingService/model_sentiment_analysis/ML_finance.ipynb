{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b438234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b76b598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "file_name='finance_data/Sentences_AllAgree.txt'\n",
    "f = open(file_name,encoding='latin1')\n",
    "data=[]\n",
    "for line in f:\n",
    "        line = line.replace('\\n', '')\n",
    "        data.append(line.split('@'))\n",
    "data=pd.DataFrame(data,columns=['contenu','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c79a73f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contenu</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the third quarter of 2010 , net sales incre...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operating profit totalled EUR 21.1 mn , up fro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>Operating result for the 12-month period decre...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>HELSINKI Thomson Financial - Shares in Cargote...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                contenu    target\n",
       "0     According to Gran , the company has no plans t...   neutral\n",
       "1     For the last quarter of 2010 , Componenta 's n...  positive\n",
       "2     In the third quarter of 2010 , net sales incre...  positive\n",
       "3     Operating profit rose to EUR 13.1 mn from EUR ...  positive\n",
       "4     Operating profit totalled EUR 21.1 mn , up fro...  positive\n",
       "...                                                 ...       ...\n",
       "2259  Operating result for the 12-month period decre...  negative\n",
       "2260  HELSINKI Thomson Financial - Shares in Cargote...  negative\n",
       "2261  LONDON MarketWatch -- Share prices ended lower...  negative\n",
       "2262  Operating profit fell to EUR 35.4 mn from EUR ...  negative\n",
       "2263  Sales in Finland decreased by 10.5 % in Januar...  negative\n",
       "\n",
       "[2264 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3555c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f31f27d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mcontenu)\n\u001b[0;32m----> 2\u001b[0m wordcloud\u001b[39m.\u001b[39;49mgenerate(text)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[39m.\u001b[39mimshow(wordcloud)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[1;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(\u001b[39mdict\u001b[39;49m(frequencies[:\u001b[39m2\u001b[39;49m]),\n\u001b[1;32m    454\u001b[0m                                    max_font_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight)\n\u001b[1;32m    455\u001b[0m     \u001b[39m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    505\u001b[0m transposed_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mTransposedFont(\n\u001b[1;32m    506\u001b[0m     font, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m    507\u001b[0m \u001b[39m# get size of resulting text\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m box_size \u001b[39m=\u001b[39m draw\u001b[39m.\u001b[39;49mtextbbox((\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m), word, font\u001b[39m=\u001b[39;49mtransposed_font, anchor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    509\u001b[0m \u001b[39m# find possible places using integral image:\u001b[39;00m\n\u001b[1;32m    510\u001b[0m result \u001b[39m=\u001b[39m occupancy\u001b[39m.\u001b[39msample_position(box_size[\u001b[39m3\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[1;32m    511\u001b[0m                                    box_size[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[1;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[1;32m    669\u001b[0m     font \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfont()\n\u001b[1;32m    670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(font, ImageFont\u001b[39m.\u001b[39mFreeTypeFont):\n\u001b[0;32m--> 671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly supported for TrueType fonts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m embedded_color \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfontmode\n\u001b[1;32m    673\u001b[0m bbox \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mgetbbox(\n\u001b[1;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[1;32m    675\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "text=' '.join(i for i in data.contenu)\n",
    "wordcloud.generate(text)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee492118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"they'd\", 'how', \"he'd\", \"they've\", 'both', 'this', 'we', 'which', 'but', 'against', 'again', 'some', 'get', \"wouldn't\", \"couldn't\", 'hers', 'also', 'from', \"i'm\", 'cannot']\n"
     ]
    }
   ],
   "source": [
    "# right the top 20 stopwords in the wordcloud dic\n",
    "print(list(WordCloud().stopwords)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "427cfcd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating profit fell to EUR 35.4 mn from EUR 68.8 mn in 2007 , including vessel sales gain of EUR 12.3 mn .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-2].contenu    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14699927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y=data.target.astype(str)\n",
    "punct_pattern=r'[\\!\"#$%&\\*+,-./:;?@^_`()|~]'\n",
    "data.loc[:,'contenu_no_puct']=data.contenu.str.replace(punct_pattern,'')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a399106c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating profit fell to EUR 35.4 mn from EUR 68.8 mn in 2007 , including vessel sales gain of EUR 12.3 mn .'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-2].contenu_no_puct    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "52921576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "# remove numbers from data set\n",
    "digitspattern = r'[0-9]'\n",
    "\n",
    "data.loc[:,'contenu_no_num_no_punc']=data.contenu_no_puct.str.replace(digitspattern,'')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "847ab96f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating profit fell to EUR 35.4 mn from EUR 68.8 mn in 2007 , including vessel sales gain of EUR 12.3 mn .'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[-2].contenu_no_num_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fad5152c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wordcloud\u001b[39m.\u001b[39;49mgenerate(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m data\u001b[39m.\u001b[39;49mcontenu_no_num_no_punc))\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mimshow(wordcloud,interpolation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[1;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(\u001b[39mdict\u001b[39;49m(frequencies[:\u001b[39m2\u001b[39;49m]),\n\u001b[1;32m    454\u001b[0m                                    max_font_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight)\n\u001b[1;32m    455\u001b[0m     \u001b[39m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    505\u001b[0m transposed_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mTransposedFont(\n\u001b[1;32m    506\u001b[0m     font, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m    507\u001b[0m \u001b[39m# get size of resulting text\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m box_size \u001b[39m=\u001b[39m draw\u001b[39m.\u001b[39;49mtextbbox((\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m), word, font\u001b[39m=\u001b[39;49mtransposed_font, anchor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    509\u001b[0m \u001b[39m# find possible places using integral image:\u001b[39;00m\n\u001b[1;32m    510\u001b[0m result \u001b[39m=\u001b[39m occupancy\u001b[39m.\u001b[39msample_position(box_size[\u001b[39m3\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[1;32m    511\u001b[0m                                    box_size[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[1;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[1;32m    669\u001b[0m     font \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfont()\n\u001b[1;32m    670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(font, ImageFont\u001b[39m.\u001b[39mFreeTypeFont):\n\u001b[0;32m--> 671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly supported for TrueType fonts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m embedded_color \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfontmode\n\u001b[1;32m    673\u001b[0m bbox \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mgetbbox(\n\u001b[1;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[1;32m    675\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "wordcloud.generate(' '.join(i for i in data.contenu_no_num_no_punc))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1cb346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will remove 'country's name (finnish is frequent here) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b350c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spacepattern=r'\\s\\s+'\n",
    "data.loc[:,'contenu_no_num_no_punc']=data.contenu_no_num_no_punc.str.replace(spacepattern,' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "713d99c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.contenu_no_num_no_punc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22863260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Operating profit rose to EUR 13.1 mn from EUR 8.7 mn in the corresponding period in 2007 representing 7.7 % of net sales .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.contenu[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5fc10f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wordcloud\u001b[39m.\u001b[39;49mgenerate(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m data\u001b[39m.\u001b[39;49mcontenu_no_num_no_punc))\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,\u001b[39m10\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mimshow(wordcloud,interpolation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[1;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(\u001b[39mdict\u001b[39;49m(frequencies[:\u001b[39m2\u001b[39;49m]),\n\u001b[1;32m    454\u001b[0m                                    max_font_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight)\n\u001b[1;32m    455\u001b[0m     \u001b[39m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/wordcloud/wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    505\u001b[0m transposed_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mTransposedFont(\n\u001b[1;32m    506\u001b[0m     font, orientation\u001b[39m=\u001b[39morientation)\n\u001b[1;32m    507\u001b[0m \u001b[39m# get size of resulting text\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m box_size \u001b[39m=\u001b[39m draw\u001b[39m.\u001b[39;49mtextbbox((\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m), word, font\u001b[39m=\u001b[39;49mtransposed_font, anchor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    509\u001b[0m \u001b[39m# find possible places using integral image:\u001b[39;00m\n\u001b[1;32m    510\u001b[0m result \u001b[39m=\u001b[39m occupancy\u001b[39m.\u001b[39msample_position(box_size[\u001b[39m3\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[1;32m    511\u001b[0m                                    box_size[\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmargin,\n\u001b[1;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[0;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[1;32m    669\u001b[0m     font \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetfont()\n\u001b[1;32m    670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(font, ImageFont\u001b[39m.\u001b[39mFreeTypeFont):\n\u001b[0;32m--> 671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOnly supported for TrueType fonts\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m embedded_color \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfontmode\n\u001b[1;32m    673\u001b[0m bbox \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mgetbbox(\n\u001b[1;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[1;32m    675\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "wordcloud.generate(' '.join(i for i in data.contenu_no_num_no_punc))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordcloud,interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99e6691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform label into numbers\n",
    "data.loc[data['target']=='neutral','target']=0\n",
    "data.loc[data['target']=='positive','target']=1\n",
    "data.loc[data['target']=='negative','target']=2\n",
    "\n",
    "y=data.target.astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "242990d2",
   "metadata": {},
   "source": [
    "#### Vectorize the text we would use Sckitis-learn has three types of vectorization \n",
    "###### we would work with CountVectorizer and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2f491036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33c9f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    doc=nlp(text)   \n",
    "    tokens=[token.lemma_ for token in doc if not (token.is_stop or token.is_punct or len(token.lemma_)<=2)]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "def POS(text):\n",
    "    doc=nlp(text)   \n",
    "    pos=[token.pos_ for token in doc if not (token.is_stop or len(token.lemma_)<=2)]\n",
    "\n",
    "    return ' '.join(pos)\n",
    "def NER(text):\n",
    "    doc=nlp(text)   \n",
    "\n",
    "    tokens=[token.lemma_ for token in doc if not (token.is_stop )]\n",
    "\n",
    "    ner=[]\n",
    "    for i in tokens:\n",
    "        j=False\n",
    "        for ent in doc.ents:\n",
    "            if i in ent.text:\n",
    "                ner.append(ent.label_)\n",
    "                j=True\n",
    "\n",
    "        if j==False:\n",
    "            ner.append(i)\n",
    "    return ' '.join(ner)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d39e23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text']=data.contenu_no_num_no_punc.apply(lambda txt : lemmatize(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8606e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pos']=data.contenu_no_num_no_punc.apply(lambda txt : POS(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac1be75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ner']=data.contenu_no_num_no_punc.apply(lambda txt : NER(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5e8722d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       accord PERSON , company plan production GPE , ...\n",
       "1       DATE DATE , ORG net sale double PERSON ORG DAT...\n",
       "2       DATE DATE , net sale increase PERCENT PERCENT ...\n",
       "3       operate profit rise ORG ORG CARDINAL mn ORG OR...\n",
       "4       operate profit total PRODUCT ORG PRODUCT mn , ...\n",
       "                              ...                        \n",
       "2259    operate result DATE DATE DATE period decrease ...\n",
       "2260    ORG ORG ORG ORG DATE ORG GPE fall sharply TIME...\n",
       "2261    ORG ORG -- share price end lower GPE DATE rebo...\n",
       "2262    operate profit fall ORG ORG ORG CARDINAL mn OR...\n",
       "2263    sale GPE GPE decrease PERCENT PERCENT PERCENT ...\n",
       "Name: ner, Length: 2264, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42ffd8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VERB_ADJ(text):\n",
    "    doc=nlp(text)   \n",
    "    pos=[token.lemma_.lower() for token in doc if  (token.is_stop==False and (token.pos_=='VERB'))]\n",
    "    return ' '.join(pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f6a1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['ner']=data.contenu_no_num_no_punc.apply(lambda txt : VERB_ADJ(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6790478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 4971)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# The CountVectorizer counts the word occurrences in each document.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "X=cv.fit_transform((data.processed_text))\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "vocab = cv.get_feature_names_out()\n",
    "docterm = pd.DataFrame(X.todense(), columns=vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2c2a5180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 4971)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=4)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2561ae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9166206515737162\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf=MultinomialNB()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "yhat = clf.predict(X_train)\n",
    "print(\"Accuracy: \",accuracy_score(y_train, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75ec3ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7969094922737306\n"
     ]
    }
   ],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55e71855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d115483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate the vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# apply the vectorizer to the corpus\n",
    "X = vectorizer.fit_transform(data.ner)\n",
    "\n",
    "# display the document-term matrix\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "docterm = pd.DataFrame(X.todense(), columns=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d9cc25ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0030</th>\n",
       "      <th>007</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>031</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>âm</th>\n",
       "      <th>ârbindelsen</th>\n",
       "      <th>än</th>\n",
       "      <th>ñhikauppa</th>\n",
       "      <th>ñinen</th>\n",
       "      <th>ñl</th>\n",
       "      <th>ñlt</th>\n",
       "      <th>ñnnen</th>\n",
       "      <th>ñrnit</th>\n",
       "      <th>ñrvi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2264 rows × 3219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  0030  007   01   02   03  031   04   05  ...   âm  \\\n",
       "0     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "3     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4     0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "...   ...  ...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "2259  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2260  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2261  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2262  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2263  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "      ârbindelsen   än  ñhikauppa  ñinen   ñl  ñlt  ñnnen  ñrnit  ñrvi  \n",
       "0             0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "1             0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "2             0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "3             0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "4             0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "...           ...  ...        ...    ...  ...  ...    ...    ...   ...  \n",
       "2259          0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "2260          0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "2261          0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "2262          0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "2263          0.0  0.0        0.0    0.0  0.0  0.0    0.0    0.0   0.0  \n",
       "\n",
       "[2264 rows x 3219 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docterm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "712c58d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 3219)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=4)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b58c805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.792932081722805\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf=MultinomialNB()\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "yhat = clf.predict(X_train)\n",
    "print(\"Accuracy: \",accuracy_score(y_train, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a529f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7373068432671082\n"
     ]
    }
   ],
   "source": [
    "yhat = clf.predict(X_test)\n",
    "print(\"Accuracy: \",accuracy_score(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e4d67d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 3183)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# The CountVectorizer counts the word occurrences in each document.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "X=cv.fit_transform((data.ner))\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "vocab = cv.get_feature_names_out()\n",
    "docterm = pd.DataFrame(X.todense(), columns=vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f41da3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1811, 3183)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2, random_state=4)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9673fdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier 0.8410596026490066\n",
      "DecisionTreeClassifier 0.8587196467991169\n",
      "GaussianNB 0.869757174392936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "ada_classifier = AdaBoostClassifier()\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "randfor_classifier = RandomForestClassifier()\n",
    "\n",
    "\n",
    "fit_ada = ada_classifier.fit(X_train, y_train)\n",
    "fit_dt = dt_classifier.fit(X_train, y_train)\n",
    "fit_gnb = randfor_classifier.fit(X_train, y_train)  # GaussianNB attend des matrices denses\n",
    "\n",
    "pred_ada = fit_ada.predict(X_test)\n",
    "pred_dt = fit_dt.predict(X_test)\n",
    "pred_gnb = fit_gnb.predict(X_test)\n",
    "\n",
    "probabilities_ada = fit_ada.predict_proba(X_test)[:, 1]\n",
    "print('AdaBoostClassifier',accuracy_score(y_test, pred_ada))\n",
    "print('DecisionTreeClassifier',accuracy_score(y_test, pred_dt))\n",
    "print('GaussianNB',accuracy_score(y_test, pred_gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6d6241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, f1_score\n",
    "recall_ada = recall_score(y_test, pred_ada,average='weighted')\n",
    "f1_ada=f1_score(y_test, pred_ada,average='weighted')\n",
    "recall_dt = recall_score(y_test, pred_dt,average='weighted')\n",
    "f1_dt=f1_score(y_test, pred_dt,average='weighted')\n",
    "recall_gnb =recall_score(y_test, pred_gnb,average='weighted')\n",
    "f1_gnb=f1_score(y_test, pred_gnb,average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d47483b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison des modèles :\n",
      "AdaBoostClassifier :\n",
      "Recall (Rappel) : 84.11%\n",
      "F1-Score : 83.46%\n",
      "\n",
      "DecisionTreeClassifier :\n",
      "Recall (Rappel) : 84.99%\n",
      "F1-Score : 84.78%\n",
      "\n",
      "GaussianNB :\n",
      "Recall (Rappel) : 85.43%\n",
      "F1-Score : 84.62%\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparaison des modèles :\")\n",
    "print(\"AdaBoostClassifier :\")\n",
    "print(\"Recall (Rappel) : {:.2f}%\".format(recall_ada * 100))\n",
    "print(\"F1-Score : {:.2f}%\".format(f1_ada * 100))\n",
    "print(\"\\nDecisionTreeClassifier :\")\n",
    "print(\"Recall (Rappel) : {:.2f}%\".format(recall_dt * 100))\n",
    "print(\"F1-Score : {:.2f}%\".format(f1_dt * 100))\n",
    "print(\"\\nGaussianNB :\")\n",
    "print(\"Recall (Rappel) : {:.2f}%\".format(recall_gnb * 100))\n",
    "print(\"F1-Score : {:.2f}%\".format(f1_gnb * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1eb4014a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sale hit record high DATE',\n",
       " 'operate profit fall CARDINAL ORG ORG ORG    CARDINAL DATE ORG ORG ORG    DATE    include vessel sale gain ORG ORG ORG CARDINAL CARDINAL mn',\n",
       " 'sale decrease DATE',\n",
       " 'go shop',\n",
       " 'efficient workplace',\n",
       " 'congratulation ! win   ORG gift card',\n",
       " 'profit rise CARDINAL CARDINAL']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pridct=['Sales hit record high last quarter','Operating profit fell to 10 EUR   from 20 EUR   in 2007   including vessel sales gain of EUR 12 3 mn ','sales decrease last quarter','i went to the shop','more efficient in workplace','Congratulations! you have won  Walmart gift card','profit rise from 100 to 2000']\n",
    "\n",
    "ner_pred=[]\n",
    "for i in pridct:\n",
    "    ner_pred.append(NER(i))\n",
    "ner_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9cc17325",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd=cv.transform(ner_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9bcf84ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=fit_dt.predict(prd)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "082ea25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model.pk','wb') as f:\n",
    "    pickle.dump(fit_dt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "67ed769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pk','rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0eac85d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(prd)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45bca428",
   "metadata": {},
   "source": [
    "### save CounterVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5782b9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CounterVectorizer.pk','wb') as f:\n",
    "    pickle.dump(cv,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e5fbbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CounterVectorizer.pk','rb') as f:\n",
    "    model=pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
